{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch book to try out different functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read lines in move_lines to build a dict of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "from data import TextReader\n",
    "from word2vec import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Data/cornell_data/movie_lines.txt\"\n",
    "reader = TextReader()\n",
    "reader.read_line_dict(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output all movie lines without indices\n",
    "reader.output_pure_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first line stored in movie_lines.txt\n",
    "print(reader.lines[1045])\n",
    "# Find the longest line (used in seq2seq for attention)\n",
    "max_length = 0\n",
    "max_line   = None\n",
    "max_key    = 0\n",
    "for key in reader.lines.keys():\n",
    "    line = reader.lines[key]\n",
    "    length = len(line.split(\" \"))\n",
    "    if length > max_length:\n",
    "        max_length = length\n",
    "        max_line   = line\n",
    "        max_key    = key\n",
    "\n",
    "print((max_length, max_key, max_line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "vocab = defaultdict(int)\n",
    "for index in reader.lines.keys():\n",
    "    line = reader.lines[index]\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        vocab[word] += 1\n",
    "\n",
    "print(len(vocab))\n",
    "print(vocab['they'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default file path is movie_conversations\n",
    "reader.read_dialogues()\n",
    "print(reader.dialogues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sanity Test on Word2Vec Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import TextReader\n",
    "from word2vec import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aufish/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/home/aufish/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# Getting word_model embedding\n",
    "word_model = word2vec()\n",
    "word_model.fit(\"/home/aufish/Documents/19SP/NeuralBot_2/Data/cornell_data/pure_movie_lines.txt\")\n",
    "word_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sanity Test for EncoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq import EncoderRNN, AttnDecoderRNN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:1\")      # index may be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "HIDDEN_SIZE = 5\n",
    "INPUT_SIZE  = 12\n",
    "BATCH_SIZE  = 10\n",
    "\n",
    "encoder = EncoderRNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE)\n",
    "decoder = AttnDecoderRNN(hidden_size=HIDDEN_SIZE, output_size=INPUT_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "# sequence length 5\n",
    "input_tensor = torch.randn(5, BATCH_SIZE, INPUT_SIZE).to(device)\n",
    "(output, hidd) = encoder(input_tensor, encoder.initHidden(batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_start = torch.randn(1, BATCH_SIZE, INPUT_SIZE).to(device)\n",
    "decoded = decoder.forward(decoding_start, decoder.initHidden(), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Brief Test on Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from word2vec import *\n",
    "# Teaching forcing is to use the target as next input instead of \n",
    "# model output to correct the training online\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "max_length = 100\n",
    "# Training function on one batch\n",
    "def train(x_tensor, t_tensor, encoder, decoder, en_optimizer, \n",
    "         de_optimizer, criterion, word_model):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "#     encoder_hidden = (encoder_hidden[0].to(device), encoder_hidden[1].to(device))\n",
    "    \n",
    "    en_optimizer.zero_grad()\n",
    "    de_optimizer.zero_grad()\n",
    "    \n",
    "    input_length  = x_tensor.size(0) # The first dimension is seq length\n",
    "    target_length = t_tensor.size(0)\n",
    "    batch_size    = x_tensor.size(1)\n",
    "    dimension     = x_tensor.size(2)\n",
    "    \n",
    "    encoder_outputs = \\\n",
    "        torch.zeros((max_length, batch_size, encoder.hidden_size), device=device)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for index in range(input_length):\n",
    "        (encoder_y, encoder_hidden) = encoder(x_tensor[index:index+1], encoder_hidden)\n",
    "        encoder_outputs[index]      = encoder_y[0]  # Pending confirmation\n",
    "        \n",
    "    decoder_input = torch.zeros((1, batch_size, dimension), device=device)\n",
    "    for i in range(batch_size):\n",
    "        decoder_input[0, i] = word_model.transform([START])\n",
    "    decoder_hidden = decoder.initHidden()\n",
    "#     decoder_hidden = (decoder_hidden[0].to(device), decoder_hidden[1].to(device))\n",
    "    \n",
    "    use_teacher_forcing = True \\\n",
    "        if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Feed the target as the next input\n",
    "        for index in range(target_length):\n",
    "            (decoder_y, decoder_hidden, attn_weights) = \\\n",
    "            decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_y[0], t_tensor[index])\n",
    "            decoder_input = t_tensor[index]\n",
    "    else:\n",
    "        for index in range(target_length):\n",
    "            (decoder_y, decoder_hidden, attn_weights) = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_y[0], t_tensor[index])\n",
    "            \n",
    "    loss.backward()\n",
    "    \n",
    "    en_optimizer.step()\n",
    "    de_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aufish/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from data import TextReader\n",
    "from seq2seq import *\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "model  = word2vec()\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([4, 500]), torch.Size([1, 500]))\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Hi what's your name?\".split()\n",
    "sentence2 = \"Tracer\".split()\n",
    "\n",
    "(input_tensor, target_tensor) = model.transform_pair(sentence1, sentence2)\n",
    "print((input_tensor.size(), target_tensor.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([100, 1, 300]), torch.Size([500, 1, 300]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38.64091110229492"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = (input_tensor.view(input_tensor.size(0), 1, input_tensor.size(1)))\n",
    "\n",
    "encoder = EncoderRNN(batch_size=1, device=device)\n",
    "decoder = AttnDecoderRNN(batch_size=1, device=device)\n",
    "\n",
    "en_optimizer = Adam(encoder.parameters(), lr=0.001)\n",
    "de_optimizer = Adam(decoder.parameters(), lr=0.001)\n",
    "criterion    = MSELoss()\n",
    "\n",
    "train(input_tensor, target_tensor, encoder, decoder, \n",
    "      en_optimizer, de_optimizer, criterion, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check if embedded model may be propagated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq import *\n",
    "class test_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test_model, self).__init__()\n",
    "        self.encoder = EncoderRNN(batch_size=1)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        output, _ = self.encoder(input_tensor, self.encoder.initHidden())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"Hi what's your name?\".split()\n",
    "\n",
    "input_tensor = model.transform(sentence1)\n",
    "input_tensor = (input_tensor.view(input_tensor.size(0), 1, input_tensor.size(1)))\n",
    "\n",
    "t_model = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 300])\n",
      "torch.Size([4, 1, 300])\n"
     ]
    }
   ],
   "source": [
    "target_tensor = torch.zeros((4, 1, 300), device=device)\n",
    "\n",
    "print(output.size())\n",
    "print(target_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0169, -0.0130,  0.0868,  ..., -0.0112,  0.0217,  0.0231]],\n",
      "\n",
      "        [[-0.0037, -0.0337,  0.0520,  ...,  0.0024, -0.0164,  0.1498]],\n",
      "\n",
      "        [[ 0.0163, -0.0585,  0.0325,  ..., -0.0369, -0.0380, -0.0079]],\n",
      "\n",
      "        [[-0.0097, -0.0557, -0.0086,  ..., -0.1367, -0.0739,  0.0959]]],\n",
      "       device='cuda:1', grad_fn=<CudnnRnnBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[ 0.0002,  0.0064,  0.0905,  ..., -0.0303,  0.0257,  0.0275]],\n",
      "\n",
      "        [[-0.0256, -0.0085,  0.0608,  ..., -0.0172,  0.0009,  0.1627]],\n",
      "\n",
      "        [[ 0.0144, -0.0393,  0.0292,  ..., -0.0401, -0.0300,  0.0117]],\n",
      "\n",
      "        [[-0.0287, -0.0391, -0.0274,  ..., -0.1509, -0.0652,  0.1007]]],\n",
      "       device='cuda:1', grad_fn=<CudnnRnnBackward>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(t_model.parameters())\n",
    "criterion = MSELoss()\n",
    "\n",
    "output   = t_model(input_tensor)\n",
    "print(output)\n",
    "loss = criterion(output, target_tensor)\n",
    "print(type(loss))\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "output_2 = t_model(input_tensor)\n",
    "print(output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6094)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check parameters before\n",
    "a = torch.tensor((1.0,2))\n",
    "b = torch.tensor((1.0,2))\n",
    "torch.log(a.dot(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
